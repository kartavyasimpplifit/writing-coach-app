import streamlit as st
from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification
from huggingface_hub import InferenceClient
from github import Github
import json
import torch

# ==========================================
# PART 1: FRONTEND CONFIG & CSS
# ==========================================

st.set_page_config(
    page_title="AI Chinese Essay Grader",
    page_icon="ğŸ“",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS
st.markdown("""
    <style>
    @import url('https://fonts.googleapis.com/css2?family=Noto+Sans+TC:wght@400;700&display=swap');
    .main { background-color: #F8F9FA; font-family: 'Noto Sans TC', sans-serif; }
    
    .stTextArea textarea {
        background-color: #FFFFFF !important;
        color: #333333 !important;
        caret-color: #333333;
        border-radius: 12px;
        border: 2px solid #E0E0E0;
        padding: 15px;
        font-size: 16px;
        font-family: "KaiTi", "SimKai", "Serif";
    }
    .stTextArea textarea:focus { border-color: #3498DB; }
    
    .score-card {
        background: white; border-radius: 15px; padding: 25px;
        text-align: center; box-shadow: 0 4px 15px rgba(0,0,0,0.05);
        height: 100%; display: flex; flex-direction: column;
        justify-content: center; align-items: center;
    }
    .score-value { font-size: 4.5rem; font-weight: 800; color: #2C3E50; margin: 10px 0; line-height: 1; }
    .score-label { font-size: 1.2rem; font-weight: 600; padding: 5px 15px; border-radius: 20px; color: white; }

    .feedback-box {
        background: white; border-radius: 15px; padding: 25px;
        box-shadow: 0 4px 15px rgba(0,0,0,0.05); border-left: 5px solid #3498DB;
        height: 100%;
    }
    
    .main-header { font-size: 2.5rem; font-weight: 700; color: #2C3E50; text-align: center; margin-top: -20px; }
    .sub-header { font-size: 1.1rem; color: #7F8C8D; text-align: center; margin-bottom: 2rem; }
    
    .stButton>button {
        width: 100%; border-radius: 30px;
        background: linear-gradient(135deg, #3498DB 0%, #2980B9 100%);
        color: white; border: none; padding: 12px 0; font-weight: bold; font-size: 18px;
    }
    .stButton>button:hover { transform: translateY(-2px); box-shadow: 0 5px 15px rgba(52,152,219,0.3); }
    </style>
""", unsafe_allow_html=True)

# ==========================================
# PART 2: BACKEND LOGIC
# ==========================================

@st.cache_resource
def load_scoring_pipeline():
    """Load BERT model locally (CPU optimized)."""
    model_id = "MirandaZhao/Finetuned_Essay_Scoring_Model_Epoch3"
    try:
        tokenizer = AutoTokenizer.from_pretrained(model_id)
        model = AutoModelForSequenceClassification.from_pretrained(model_id)
        return pipeline("text-classification", model=model, tokenizer=tokenizer, device=-1)
    except Exception as e:
        st.error(f"âš ï¸ Scoring Model Error: {e}")
        return None

def calculate_weighted_score(predictions):
    """Calculate 0-100 score with multi-language support."""
    label_weights = {
        "ä¸åŠæ ¼": 45, "Needs Improvement": 45, "LABEL_0": 45,
        "è‰¯å¥½": 75, "Good": 75, "LABEL_1": 75,
        "å„ªç§€": 95, "Excellent": 95, "LABEL_2": 95,
        "ä¼˜ç§€": 95
    }

    weighted_score = 0
    total_confidence = 0
    
    for p in predictions:
        l = p['label']
        c = p['score']
        for key, val in label_weights.items():
            if key in l:
                weighted_score += (val * c)
                total_confidence += c
                break
    
    if total_confidence == 0: return 0, "Error", "#999"

    final_score = int(weighted_score)
    
    if final_score >= 85:
        return final_score, "Excellent (å„ªç§€)", "#2ECC71"
    elif final_score >= 60:
        return final_score, "Good (è‰¯å¥½)", "#F39C12"
    else:
        return final_score, "Needs Improvement (éœ€æ”¹é€²)", "#E74C3C"

def generate_feedback(essay, score, level, hf_token):
    """Generate feedback using Qwen-72B via API."""
    if not hf_token: return "âš ï¸ Token missing. Please add your Hugging Face token."
    
    client = InferenceClient(model="Qwen/Qwen2.5-72B-Instruct", token=hf_token)
    prompt = f"""
    Role: Experienced Chinese teacher.
    Task: Grade this Primary Student essay.
    Essay: "{essay}"
    Score: {score}/100 ({level})
    Instructions:
    1. Tone: Encouraging.
    2. Format: ğŸŒŸ Highlights (1 sentence), ğŸ’¡ Suggestion (1 tip for 'Show Don't Tell'), âœï¸ Correction (fix 1 vocab).
    3. Language: Traditional Chinese.
    4. Length: Under 150 words.
    """
    try:
        msg = [{"role": "user", "content": prompt}]
        res = client.chat_completion(msg, max_tokens=500, temperature=0.7)
        return res.choices[0].message.content
    except Exception as e:
        return f"âš ï¸ Feedback Error: {str(e)}"

def save_to_github(essay, score, level, correction):
    """Saves teacher feedback to a JSON file in YOUR GitHub Repo."""
    
    # --- âœ… UPDATED REPO NAME ---
    REPO_NAME = "kartavyasimpplifit/V2_2510gnam08_Atri_Kartavya_isom5240-storytelling-app"
    
    if 'GITHUB_TOKEN' not in st.secrets:
        st.error("Missing GITHUB_TOKEN in Secrets.")
        return False

    g = Github(st.secrets["GITHUB_TOKEN"])
    try:
        repo = g.get_repo(REPO_NAME)
        file_path = "data/feedback.json"
        
        try:
            contents = repo.get_contents(file_path)
            existing_data = json.loads(contents.decoded_content.decode())
        except:
            existing_data = []
            
        new_entry = {
            "essay": essay,
            "ai_score": score,
            "ai_level": level,
            "teacher_correction": correction
        }
        existing_data.append(new_entry)
        
        updated_content = json.dumps(existing_data, indent=2, ensure_ascii=False)
        
        if 'contents' in locals():
            repo.update_file(file_path, "Add teacher feedback", updated_content, contents.sha)
        else:
            repo.create_file(file_path, "Init database", updated_content)
            
        return True
    except Exception as e:
        st.error(f"GitHub Error: {e}")
        return False

# ==========================================
# PART 3: MAIN APP
# ==========================================

def main():
    with st.sidebar:
        st.image("https://cdn-icons-png.flaticon.com/512/3429/3429414.png", width=80)
        st.markdown("## ğŸ‘©â€ğŸ« Teacher's Desk")
        if 'HF_TOKEN' in st.secrets:
            hf_token = st.secrets['HF_TOKEN']
            st.success("AI Token Loaded ğŸ”’")
        else:
            hf_token = st.text_input("Enter HF Token", type="password")
        
        st.info("**System Status:**\nğŸŸ¢ Scoring (Local)\nğŸŸ¢ Feedback (Remote)\nğŸŸ¢ Database (GitHub)")

    st.markdown('<div class="main-header">ğŸ“ AI Chinese Essay Grader</div>', unsafe_allow_html=True)
    st.markdown('<div class="sub-header">Instant Scoring & Personalized Feedback</div>', unsafe_allow_html=True)

    essay_text = st.text_area("ğŸ“ Paste Student Essay Here:", height=250, placeholder="åœ¨æ­¤è¼¸å…¥ä½œæ–‡...")
    
    col_grade, _ = st.columns([1, 3])
    with col_grade:
        grade_btn = st.button("âœ¨ Grade Essay")

    if 'result_generated' not in st.session_state:
        st.session_state.result_generated = False

    if grade_btn:
        if not essay_text.strip():
            st.toast("âš ï¸ Input empty!", icon="ğŸš«")
            return

        progress_text = st.empty()
        bar = st.progress(0)

        scorer = load_scoring_pipeline()
        if scorer:
            progress_text.text("ğŸ§  Analyzing structure...")
            bar.progress(30)
            try:
                preds = scorer(essay_text, truncation=True, max_length=512, top_k=None)
                score, level_text, color = calculate_weighted_score(preds)
                
                st.session_state.score = score
                st.session_state.level_text = level_text
                st.session_state.color = color
                st.session_state.essay = essay_text
                
            except Exception as e:
                st.error(f"Scoring Failed: {e}")
                return

            progress_text.text("âœï¸ Drafting comments...")
            bar.progress(70)
            feedback = generate_feedback(essay_text, score, level_text, hf_token)
            st.session_state.feedback = feedback
            
            bar.progress(100)
            progress_text.empty()
            bar.empty()
            st.session_state.result_generated = True

    if st.session_state.result_generated:
        st.markdown("---")
        c1, c2 = st.columns([1, 2], gap="large")

        with c1:
            st.markdown(f"""
            <div class="score-card" style="border-top: 6px solid {st.session_state.color};">
                <div style="color: #888; font-weight: bold;">PROFICIENCY</div>
                <div class="score-value">{st.session_state.score}</div>
                <div class="score-label" style="background-color: {st.session_state.color};">{st.session_state.level_text.split('(')[0]}</div>
            </div>
            """, unsafe_allow_html=True)

        with c2:
            st.markdown(f"""
            <div class="feedback-box">
                <h3 style="margin-top:0; color:#2C3E50;">ğŸ‘©â€ğŸ« Teacher's Feedback</h3>
                <div style="color: #555; line-height: 1.6; font-size: 1.1rem;">
                    {st.session_state.feedback}
                </div>
            </div>
            """, unsafe_allow_html=True)

        st.markdown("---")
        st.subheader("ğŸ§ Help Improve the AI")
        
        with st.form("feedback_form"):
            st.write(f"The AI graded this as: **{st.session_state.level_text}**")
            correction = st.radio(
                "Is this grade correct?",
                ["âœ… Yes, correct", "âš ï¸ No, should be 'Needs Improvement'", "âš ï¸ No, should be 'Good'", "âš ï¸ No, should be 'Excellent'"],
                horizontal=True
            )
            submit_feed = st.form_submit_button("Submit Feedback to Database")
            
            if submit_feed:
                final_label = correction
                if "Yes" in correction:
                    final_label = st.session_state.level_text.split('(')[0]
                else:
                    final_label = correction.replace("âš ï¸ No, should be ", "").replace("'", "")
                
                if save_to_github(st.session_state.essay, st.session_state.score, st.session_state.level_text, final_label):
                    st.success("âœ… Feedback saved to GitHub! The model will learn from this next week.")
                else:
                    st.error("âŒ Failed to save. Check your GITHUB_TOKEN.")

if __name__ == "__main__":
    main()
